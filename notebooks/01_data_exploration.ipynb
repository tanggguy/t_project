{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01. Exploration et Validation des Données\n",
    "\n",
    "**Objectif :** Ce notebook sert à valider le `DataManager` (tâche 2.1) et à effectuer une première analyse exploratoire des données (tâche 2.4). \n",
    "\n",
    "Nous allons :\n",
    "1.  Tester le chargement d'un seul ticker (`AAPL`).\n",
    "2.  Afficher les statistiques descriptives.\n",
    "3.  Visualiser les données (OHLCV + Indicateurs) de manière interactive.\n",
    "4.  Vérifier la qualité des données (NaNs, outliers).\n",
    "5.  Tester le téléchargement en batch d'une liste de 10 tickers (S&P 500 + CAC 40)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Root (ajouté au sys.path): c:\\Users\\saill\\Desktop\\t_project\n",
      "Modules importés avec succès.\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Bibliothèques natives ---\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# --- 2. Bibliothèques tierces ---\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# --- Configuration du Chemin ---\n",
    "# Ajoute la racine du projet au PYTHONPATH pour que les imports (utils, etc.) fonctionnent\n",
    "try:\n",
    "    # Si exécuté depuis 'notebooks/'\n",
    "    PROJECT_ROOT = Path(__file__).resolve().parent.parent\n",
    "except NameError:\n",
    "    # Si exécuté interactivement (cas le plus courant)\n",
    "    PROJECT_ROOT = Path.cwd().parent\n",
    "\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "print(f\"Project Root (ajouté au sys.path): {PROJECT_ROOT}\")\n",
    "\n",
    "# --- 3. Imports locaux du projet ---\n",
    "from utils.data_manager import DataManager\n",
    "from utils.data_processor import add_returns # Tâche 2.3\n",
    "\n",
    "print(\"Modules importés avec succès.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Test de Téléchargement (Ticker Unique)\n",
    "\n",
    "Nous initialisons `DataManager` et chargeons les données pour `AAPL` sur une période de 3 ans. \n",
    "\n",
    "Nous forçons `use_cache=False` pour ce premier test afin de valider le processus de téléchargement et de sauvegarde. Nous activons `add_indicators=True` pour vérifier que le `DataManager` ajoute bien les colonnes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-01 12:48:53\u001b[0m - \u001b[34mutils.config_loader\u001b[0m - \u001b[1;30mINFO\u001b[0m - Chargement des paramètres globaux depuis : c:\\Users\\saill\\Desktop\\t_project\\config\\settings.yaml\n",
      "\u001b[32m2025-11-01 12:48:53\u001b[0m - \u001b[34mutils.data_manager\u001b[0m - \u001b[1;30mINFO\u001b[0m - DataManager initialisé. Cache: C:\\Users\\saill\\Desktop\\t_project\\data\\cache. Timezone: Europe/Paris\n",
      "\u001b[32m2025-11-01 12:48:53\u001b[0m - \u001b[34mutils.data_manager\u001b[0m - \u001b[1;30mINFO\u001b[0m - Téléchargement pour AAPL (plage par défaut : 2020-01-01 à 2025-10-31)...\n",
      "\u001b[32m2025-11-01 12:48:53\u001b[0m - \u001b[34mutils.data_manager\u001b[0m - \u001b[1;30mINFO\u001b[0m - Téléchargement de AAPL (2020-01-01 à 2025-10-31, 1d)...\n",
      "\u001b[32m2025-11-01 12:48:53\u001b[0m - \u001b[34mutils.data_manager\u001b[0m - \u001b[1;30mINFO\u001b[0m - Données téléchargées avec succès pour AAPL (1466 lignes).\n",
      "\u001b[32m2025-11-01 12:48:53\u001b[0m - \u001b[34mutils.data_manager\u001b[0m - \u001b[1;30mINFO\u001b[0m - [OK] Données prêtes pour AAPL (753 lignes de 2022-01-01 à 2024-12-31).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 753 entries, 2022-01-03 06:00:00+01:00 to 2024-12-31 06:00:00+01:00\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   open    753 non-null    float64\n",
      " 1   high    753 non-null    float64\n",
      " 2   low     753 non-null    float64\n",
      " 3   close   753 non-null    float64\n",
      " 4   volume  753 non-null    int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 35.3 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-03 06:00:00+01:00</th>\n",
       "      <td>174.345053</td>\n",
       "      <td>179.296091</td>\n",
       "      <td>174.227410</td>\n",
       "      <td>178.443130</td>\n",
       "      <td>104487900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-04 06:00:00+01:00</th>\n",
       "      <td>179.050948</td>\n",
       "      <td>179.354870</td>\n",
       "      <td>175.609725</td>\n",
       "      <td>176.178360</td>\n",
       "      <td>99310400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-05 06:00:00+01:00</th>\n",
       "      <td>176.090142</td>\n",
       "      <td>176.639165</td>\n",
       "      <td>171.217539</td>\n",
       "      <td>171.492050</td>\n",
       "      <td>94537600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-06 06:00:00+01:00</th>\n",
       "      <td>169.315582</td>\n",
       "      <td>171.864636</td>\n",
       "      <td>168.276357</td>\n",
       "      <td>168.629303</td>\n",
       "      <td>96904000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-07 06:00:00+01:00</th>\n",
       "      <td>169.501881</td>\n",
       "      <td>170.727385</td>\n",
       "      <td>167.678331</td>\n",
       "      <td>168.795990</td>\n",
       "      <td>86709100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 open        high         low       close  \\\n",
       "Date                                                                        \n",
       "2022-01-03 06:00:00+01:00  174.345053  179.296091  174.227410  178.443130   \n",
       "2022-01-04 06:00:00+01:00  179.050948  179.354870  175.609725  176.178360   \n",
       "2022-01-05 06:00:00+01:00  176.090142  176.639165  171.217539  171.492050   \n",
       "2022-01-06 06:00:00+01:00  169.315582  171.864636  168.276357  168.629303   \n",
       "2022-01-07 06:00:00+01:00  169.501881  170.727385  167.678331  168.795990   \n",
       "\n",
       "                              volume  \n",
       "Date                                  \n",
       "2022-01-03 06:00:00+01:00  104487900  \n",
       "2022-01-04 06:00:00+01:00   99310400  \n",
       "2022-01-05 06:00:00+01:00   94537600  \n",
       "2022-01-06 06:00:00+01:00   96904000  \n",
       "2022-01-07 06:00:00+01:00   86709100  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm = DataManager()\n",
    "\n",
    "ticker = \"AAPL\"\n",
    "start_date = \"2022-01-01\"\n",
    "end_date = \"2024-12-31\"\n",
    "\n",
    "df_aapl = dm.get_data(\n",
    "    ticker=ticker,\n",
    "    start_date=start_date,\n",
    "    end_date=end_date,\n",
    "    use_cache=False,      # Force le téléchargement pour ce test\n",
    ")\n",
    "\n",
    "df_aapl.info()\n",
    "df_aapl.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Statistiques Descriptives\n",
    "\n",
    "Un simple `.describe()` nous donne un aperçu rapide de la distribution des prix, des volumes et des indicateurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         open    high     low   close          volume\n",
      "count  753.00  753.00  753.00  753.00          753.00\n",
      "mean   176.17  178.04  174.48  176.36   68,077,423.51\n",
      "std     29.47   29.46   29.49   29.54   28,346,260.21\n",
      "min    124.26  125.99  122.44  123.28   23,234,700.00\n",
      "25%    153.15  155.37  151.45  153.70   48,714,100.00\n",
      "50%    171.22  172.52  169.77  171.51   62,199,000.00\n",
      "75%    189.88  191.46  188.81  189.95   80,546,200.00\n",
      "max    257.28  259.18  256.72  258.10  318,679,900.00\n"
     ]
    }
   ],
   "source": [
    "# Appliquer un formatage pour une meilleure lisibilité\n",
    "print(df_aapl.describe().apply(lambda s: s.apply('{:,.2f}'.format)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonnes 'BBands' réellement trouvées dans le DataFrame :\n",
      "[]\n",
      "Index(['open', 'high', 'low', 'close', 'volume'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "bbands_cols = [col for col in df_aapl.columns if 'bb' in col.upper()]\n",
    "\n",
    "print(\"Colonnes 'BBands' réellement trouvées dans le DataFrame :\")\n",
    "print(bbands_cols)\n",
    "print(df_aapl.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualisation des Données (Plotly)\n",
    "\n",
    "Nous vérifions visuellement les données OHLCV ainsi que les indicateurs ajoutés par `DataManager` :\n",
    "* **Prix** + **Bandes de Bollinger** (`BBU_20_2.0`, `BBL_20_2.0`)\n",
    "* **Volume**\n",
    "* **MACD** (`MACD_12_26_9`, `MACDs_12_26_9`, `MACDh_12_26_9`)\n",
    "* **RSI** (`RSI_14`)\n",
    "\n",
    "*(Note: L'ATR `ATRr_14` est calculé mais n'est pas affiché ici pour plus de clarté)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'BBU_20_2.0_2.0'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saill\\Desktop\\t_project\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'BBU_20_2.0_2.0'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     11\u001b[39m fig.add_trace(go.Candlestick(x=df_aapl.index,\n\u001b[32m     12\u001b[39m                 \u001b[38;5;28mopen\u001b[39m=df_aapl[\u001b[33m'\u001b[39m\u001b[33mopen\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     13\u001b[39m                 high=df_aapl[\u001b[33m'\u001b[39m\u001b[33mhigh\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     14\u001b[39m                 low=df_aapl[\u001b[33m'\u001b[39m\u001b[33mlow\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     15\u001b[39m                 close=df_aapl[\u001b[33m'\u001b[39m\u001b[33mclose\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     16\u001b[39m                 name=\u001b[33m'\u001b[39m\u001b[33mOHLC\u001b[39m\u001b[33m'\u001b[39m), row=\u001b[32m1\u001b[39m, col=\u001b[32m1\u001b[39m)\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# LIGNE CORRIGÉE : Utilise 'BBU_20_2.0_2.0'\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m fig.add_trace(go.Scatter(x=df_aapl.index, y=\u001b[43mdf_aapl\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mBBU_20_2.0_2.0\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m, \n\u001b[32m     20\u001b[39m                          line=\u001b[38;5;28mdict\u001b[39m(color=\u001b[33m'\u001b[39m\u001b[33mblue\u001b[39m\u001b[33m'\u001b[39m, width=\u001b[32m1\u001b[39m, dash=\u001b[33m'\u001b[39m\u001b[33mdash\u001b[39m\u001b[33m'\u001b[39m), \n\u001b[32m     21\u001b[39m                          name=\u001b[33m'\u001b[39m\u001b[33mBB Upper\u001b[39m\u001b[33m'\u001b[39m), row=\u001b[32m1\u001b[39m, col=\u001b[32m1\u001b[39m)\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# LIGNE CORRIGÉE : Utilise 'BBL_20_2.0_2.0'\u001b[39;00m\n\u001b[32m     24\u001b[39m fig.add_trace(go.Scatter(x=df_aapl.index, y=df_aapl[\u001b[33m'\u001b[39m\u001b[33mBBL_20_2.0_2.0\u001b[39m\u001b[33m'\u001b[39m], \n\u001b[32m     25\u001b[39m                          line=\u001b[38;5;28mdict\u001b[39m(color=\u001b[33m'\u001b[39m\u001b[33mblue\u001b[39m\u001b[33m'\u001b[39m, width=\u001b[32m1\u001b[39m, dash=\u001b[33m'\u001b[39m\u001b[33mdash\u001b[39m\u001b[33m'\u001b[39m), \n\u001b[32m     26\u001b[39m                          name=\u001b[33m'\u001b[39m\u001b[33mBB Lower\u001b[39m\u001b[33m'\u001b[39m, fill=\u001b[33m'\u001b[39m\u001b[33mtonexty\u001b[39m\u001b[33m'\u001b[39m, fillcolor=\u001b[33m'\u001b[39m\u001b[33mrgba(0,0,255,0.05)\u001b[39m\u001b[33m'\u001b[39m), row=\u001b[32m1\u001b[39m, col=\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saill\\Desktop\\t_project\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4112\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4115\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saill\\Desktop\\t_project\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'BBU_20_2.0_2.0'"
     ]
    }
   ],
   "source": [
    "fig = make_subplots(\n",
    "    rows=4, \n",
    "    cols=1, \n",
    "    shared_xaxes=True, \n",
    "    vertical_spacing=0.03,\n",
    "    subplot_titles=('Prix (AAPL) avec Bandes de Bollinger', 'Volume', 'MACD', 'RSI'),\n",
    "    row_heights=[0.5, 0.1, 0.2, 0.2]\n",
    ")\n",
    "\n",
    "# --- Rangée 1: Prix + Bandes de Bollinger ---\n",
    "fig.add_trace(go.Candlestick(x=df_aapl.index,\n",
    "                open=df_aapl['open'],\n",
    "                high=df_aapl['high'],\n",
    "                low=df_aapl['low'],\n",
    "                close=df_aapl['close'],\n",
    "                name='OHLC'), row=1, col=1)\n",
    "\n",
    "# LIGNE CORRIGÉE : Utilise 'BBU_20_2.0_2.0'\n",
    "fig.add_trace(go.Scatter(x=df_aapl.index, y=df_aapl['BBU_20_2.0_2.0'], \n",
    "                         line=dict(color='blue', width=1, dash='dash'), \n",
    "                         name='BB Upper'), row=1, col=1)\n",
    "\n",
    "# LIGNE CORRIGÉE : Utilise 'BBL_20_2.0_2.0'\n",
    "fig.add_trace(go.Scatter(x=df_aapl.index, y=df_aapl['BBL_20_2.0_2.0'], \n",
    "                         line=dict(color='blue', width=1, dash='dash'), \n",
    "                         name='BB Lower', fill='tonexty', fillcolor='rgba(0,0,255,0.05)'), row=1, col=1)\n",
    "\n",
    "# --- Rangée 2: Volume ---\n",
    "fig.add_trace(go.Bar(x=df_aapl.index, y=df_aapl['volume'], name='Volume', marker_color='grey'), row=2, col=1)\n",
    "\n",
    "# --- Rangée 3: MACD ---\n",
    "fig.add_trace(go.Scatter(x=df_aapl.index, y=df_aapl['MACD_12_26_9'], \n",
    "                         line=dict(color='green', width=1.5), name='MACD'), row=3, col=1)\n",
    "fig.add_trace(go.Scatter(x=df_aapl.index, y=df_aapl['MACDs_12_26_9'], \n",
    "                         line=dict(color='red', width=1.5), name='Signal'), row=3, col=1)\n",
    "fig.add_trace(go.Bar(x=df_aapl.index, y=df_aapl['MACDh_12_26_9'], \n",
    "                      name='Histogramme', marker_color='grey', opacity=0.5), row=3, col=1)\n",
    "\n",
    "# --- Rangée 4: RSI ---\n",
    "fig.add_trace(go.Scatter(x=df_aapl.index, y=df_aapl['RSI_14'], \n",
    "                         line=dict(color='purple', width=1.5), name='RSI'), row=4, col=1)\n",
    "fig.add_hline(y=70, line_dash=\"dash\", line_color=\"red\", row=4, col=1)\n",
    "fig.add_hline(y=30, line_dash=\"dash\", line_color=\"green\", row=4, col=1)\n",
    "\n",
    "# --- Mise en Forme ---\n",
    "fig.update_layout(\n",
    "    height=1000, \n",
    "    title_text=f\"Analyse Technique Interactive - {ticker}\",\n",
    "    xaxis_rangeslider_visible=False,\n",
    "    legend_orientation='h',\n",
    "    legend_yanchor='bottom',\n",
    "    legend_y=1.01,\n",
    "    legend_xanchor='left',\n",
    "    legend_x=0\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Vérification de la Qualité des Données\n",
    "\n",
    "Nous vérifions deux points critiques :\n",
    "\n",
    "1.  **Données Manquantes (NaNs) :** `DataManager` est censé supprimer les `NaNs` initiaux après le calcul des indicateurs. Le total des NaNs doit être 0.\n",
    "2.  **Outliers (Rendements) :** Nous utilisons `data_processor.add_returns` pour calculer les rendements journaliers et nous vérifions les quantiles extrêmes (1% et 99%). Des valeurs extrêmes (> 15-20%) pourraient indiquer des problèmes de données (splits non ajustés, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total des valeurs NaN dans le DataFrame: 0\n",
      "Vérification NaN: SUCCÈS. (Les périodes de chauffe des indicateurs ont été purgées)\n",
      "\n",
      "--- Statistiques des Rendements Journaliers (pct_return) ---\n",
      "count    753.0000\n",
      "mean       0.0006\n",
      "std        0.0171\n",
      "min       -0.0587\n",
      "1%        -0.0445\n",
      "5%        -0.0272\n",
      "25%       -0.0084\n",
      "50%        0.0011\n",
      "75%        0.0097\n",
      "95%        0.0258\n",
      "99%        0.0442\n",
      "max        0.0890\n",
      "Name: pct_return, dtype: object\n",
      "\n",
      "Rendement journalier absolu MAX: 8.90%\n",
      "Vérification Outliers (Rendements): SUCCÈS.\n"
     ]
    }
   ],
   "source": [
    "# 1. Vérification des NaNs\n",
    "nan_count = df_aapl.isnull().sum().sum()\n",
    "print(f\"Total des valeurs NaN dans le DataFrame: {nan_count}\")\n",
    "\n",
    "if nan_count == 0:\n",
    "    print(\"Vérification NaN: SUCCÈS. (Les périodes de chauffe des indicateurs ont été purgées)\")\n",
    "else:\n",
    "    print(\"Vérification NaN: ÉCHEC.\")\n",
    "    print(df_aapl.isnull().sum())\n",
    "\n",
    "# 2. Détection d'outliers (via les rendements)\n",
    "df_aapl_returns = add_returns(df_aapl[['open', 'high', 'low', 'close', 'volume']].copy()) # Utilise une copie sans indicateurs\n",
    "\n",
    "print(\"\\n--- Statistiques des Rendements Journaliers (pct_return) ---\")\n",
    "print(df_aapl_returns['pct_return'].describe(percentiles=[.01, .05, .25, .75, .95, .99]).apply(\"{:,.4f}\".format))\n",
    "\n",
    "max_return = df_aapl_returns['pct_return'].abs().max()\n",
    "print(f\"\\nRendement journalier absolu MAX: {max_return:.2%}\")\n",
    "if max_return > 0.25: # Seuil arbitraire de 25%\n",
    "    print(\"AVERTISSEMENT: Détection d'un rendement journalier extrême > 25%. Vérification manuelle requise.\")\n",
    "else:\n",
    "    print(\"Vérification Outliers (Rendements): SUCCÈS.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test de Téléchargement en Batch (5-10 Tickers)\n",
    "\n",
    "Enfin, nous testons la capacité du `DataManager` à charger une liste de tickers (5 US, 5 FR). \n",
    "\n",
    "Pour ce test, nous utilisons `use_cache=True` (le comportement par défaut) pour vérifier que `AAPL` est bien lu depuis le cache (devrait être quasi-instantané) et que les 9 autres sont téléchargés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-01 12:45:08\u001b[0m - \u001b[34mutils.data_manager\u001b[0m - \u001b[1;30mINFO\u001b[0m - [OK] Données pour AAPL chargées depuis le cache.\n",
      "\u001b[32m2025-11-01 12:45:08\u001b[0m - \u001b[34mutils.data_manager\u001b[0m - \u001b[1;30mINFO\u001b[0m - [OK] Données prêtes pour AAPL (753 lignes de 2022-01-01 à 2024-12-31).\n",
      "\u001b[32m2025-11-01 12:45:09\u001b[0m - \u001b[34mutils.data_manager\u001b[0m - \u001b[1;30mWARNING\u001b[0m - \u001b[33mIndex invalide dans C:\\Users\\saill\\Desktop\\t_project\\data\\cache\\MSFT_1d.csv. Re-téléchargement.\u001b[0m\n",
      "\u001b[32m2025-11-01 12:45:09\u001b[0m - \u001b[34mutils.data_manager\u001b[0m - \u001b[1;30mINFO\u001b[0m - Téléchargement pour MSFT (plage par défaut : 2020-01-01 à 2025-10-31)...\n",
      "\u001b[32m2025-11-01 12:45:09\u001b[0m - \u001b[34mutils.data_manager\u001b[0m - \u001b[1;30mINFO\u001b[0m - Téléchargement de MSFT (2020-01-01 à 2025-10-31, 1d)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Début du test de chargement en batch pour 10 tickers...\n",
      "--- Chargement AAPL ---\n",
      "SUCCÈS: 753 lignes chargées pour AAPL\n",
      "--- Chargement MSFT ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-01 12:45:09\u001b[0m - \u001b[34mutils.data_manager\u001b[0m - \u001b[1;30mINFO\u001b[0m - Données téléchargées avec succès pour MSFT (1466 lignes).\n",
      "\u001b[32m2025-11-01 12:45:09\u001b[0m - \u001b[34mutils.data_manager\u001b[0m - \u001b[1;30mINFO\u001b[0m - [OK] Données prêtes pour MSFT (753 lignes de 2022-01-01 à 2024-12-31).\n",
      "\u001b[32m2025-11-01 12:45:09\u001b[0m - \u001b[34mutils.data_manager\u001b[0m - \u001b[1;30mWARNING\u001b[0m - \u001b[33mIndex invalide dans C:\\Users\\saill\\Desktop\\t_project\\data\\cache\\GOOG_1d.csv. Re-téléchargement.\u001b[0m\n",
      "\u001b[32m2025-11-01 12:45:09\u001b[0m - \u001b[34mutils.data_manager\u001b[0m - \u001b[1;30mINFO\u001b[0m - Téléchargement pour GOOG (plage par défaut : 2020-01-01 à 2025-10-31)...\n",
      "\u001b[32m2025-11-01 12:45:09\u001b[0m - \u001b[34mutils.data_manager\u001b[0m - \u001b[1;30mINFO\u001b[0m - Téléchargement de GOOG (2020-01-01 à 2025-10-31, 1d)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCÈS: 753 lignes chargées pour MSFT\n",
      "--- Chargement GOOG ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-01 12:45:09\u001b[0m - \u001b[34mutils.data_manager\u001b[0m - \u001b[1;30mINFO\u001b[0m - Données téléchargées avec succès pour GOOG (1466 lignes).\n",
      "\u001b[32m2025-11-01 12:45:09\u001b[0m - \u001b[34mutils.data_manager\u001b[0m - \u001b[1;30mINFO\u001b[0m - [OK] Données prêtes pour GOOG (753 lignes de 2022-01-01 à 2024-12-31).\n",
      "\u001b[32m2025-11-01 12:45:09\u001b[0m - \u001b[34mutils.data_manager\u001b[0m - \u001b[1;30mINFO\u001b[0m - [OK] Données pour TSLA chargées depuis le cache.\n",
      "\u001b[32m2025-11-01 12:45:09\u001b[0m - \u001b[34mutils.data_manager\u001b[0m - \u001b[1;30mINFO\u001b[0m - [OK] Données prêtes pour TSLA (753 lignes de 2022-01-01 à 2024-12-31).\n",
      "\u001b[32m2025-11-01 12:45:09\u001b[0m - \u001b[34mutils.data_manager\u001b[0m - \u001b[1;30mWARNING\u001b[0m - \u001b[33mIndex invalide dans C:\\Users\\saill\\Desktop\\t_project\\data\\cache\\NVDA_1d.csv. Re-téléchargement.\u001b[0m\n",
      "\u001b[32m2025-11-01 12:45:09\u001b[0m - \u001b[34mutils.data_manager\u001b[0m - \u001b[1;30mINFO\u001b[0m - Téléchargement pour NVDA (plage par défaut : 2020-01-01 à 2025-10-31)...\n",
      "\u001b[32m2025-11-01 12:45:09\u001b[0m - \u001b[34mutils.data_manager\u001b[0m - \u001b[1;30mINFO\u001b[0m - Téléchargement de NVDA (2020-01-01 à 2025-10-31, 1d)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCÈS: 753 lignes chargées pour GOOG\n",
      "--- Chargement TSLA ---\n",
      "SUCCÈS: 753 lignes chargées pour TSLA\n",
      "--- Chargement NVDA ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-01 12:45:09\u001b[0m - \u001b[34mutils.data_manager\u001b[0m - \u001b[1;30mINFO\u001b[0m - Données téléchargées avec succès pour NVDA (1466 lignes).\n",
      "\u001b[32m2025-11-01 12:45:09\u001b[0m - \u001b[34mutils.data_manager\u001b[0m - \u001b[1;30mINFO\u001b[0m - [OK] Données prêtes pour NVDA (753 lignes de 2022-01-01 à 2024-12-31).\n",
      "\u001b[32m2025-11-01 12:45:09\u001b[0m - \u001b[34mutils.data_manager\u001b[0m - \u001b[1;30mWARNING\u001b[0m - \u001b[33mIndex invalide dans C:\\Users\\saill\\Desktop\\t_project\\data\\cache\\MC.PA_1d.csv. Re-téléchargement.\u001b[0m\n",
      "\u001b[32m2025-11-01 12:45:09\u001b[0m - \u001b[34mutils.data_manager\u001b[0m - \u001b[1;30mINFO\u001b[0m - Téléchargement pour MC.PA (plage par défaut : 2020-01-01 à 2025-10-31)...\n",
      "\u001b[32m2025-11-01 12:45:09\u001b[0m - \u001b[34mutils.data_manager\u001b[0m - \u001b[1;30mINFO\u001b[0m - Téléchargement de MC.PA (2020-01-01 à 2025-10-31, 1d)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCÈS: 753 lignes chargées pour NVDA\n",
      "--- Chargement MC.PA ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-01 12:45:10\u001b[0m - \u001b[34mutils.data_manager\u001b[0m - \u001b[1;30mINFO\u001b[0m - Données téléchargées avec succès pour MC.PA (1496 lignes).\n",
      "\u001b[32m2025-11-01 12:45:10\u001b[0m - \u001b[34mutils.data_manager\u001b[0m - \u001b[1;30mINFO\u001b[0m - [OK] Données prêtes pour MC.PA (768 lignes de 2022-01-01 à 2024-12-31).\n",
      "\u001b[32m2025-11-01 12:45:10\u001b[0m - \u001b[34mutils.data_manager\u001b[0m - \u001b[1;30mWARNING\u001b[0m - \u001b[33mIndex invalide dans C:\\Users\\saill\\Desktop\\t_project\\data\\cache\\TTE.PA_1d.csv. Re-téléchargement.\u001b[0m\n",
      "\u001b[32m2025-11-01 12:45:10\u001b[0m - \u001b[34mutils.data_manager\u001b[0m - \u001b[1;30mINFO\u001b[0m - Téléchargement pour TTE.PA (plage par défaut : 2020-01-01 à 2025-10-31)...\n",
      "\u001b[32m2025-11-01 12:45:10\u001b[0m - \u001b[34mutils.data_manager\u001b[0m - \u001b[1;30mINFO\u001b[0m - Téléchargement de TTE.PA (2020-01-01 à 2025-10-31, 1d)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCÈS: 768 lignes chargées pour MC.PA\n",
      "--- Chargement TTE.PA ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-01 12:45:10\u001b[0m - \u001b[34mutils.data_manager\u001b[0m - \u001b[1;30mINFO\u001b[0m - Données téléchargées avec succès pour TTE.PA (1496 lignes).\n",
      "\u001b[32m2025-11-01 12:45:10\u001b[0m - \u001b[34mutils.data_manager\u001b[0m - \u001b[1;30mINFO\u001b[0m - [OK] Données prêtes pour TTE.PA (768 lignes de 2022-01-01 à 2024-12-31).\n",
      "\u001b[32m2025-11-01 12:45:10\u001b[0m - \u001b[34mutils.data_manager\u001b[0m - \u001b[1;30mWARNING\u001b[0m - \u001b[33mIndex invalide dans C:\\Users\\saill\\Desktop\\t_project\\data\\cache\\SAN.PA_1d.csv. Re-téléchargement.\u001b[0m\n",
      "\u001b[32m2025-11-01 12:45:10\u001b[0m - \u001b[34mutils.data_manager\u001b[0m - \u001b[1;30mINFO\u001b[0m - Téléchargement pour SAN.PA (plage par défaut : 2020-01-01 à 2025-10-31)...\n",
      "\u001b[32m2025-11-01 12:45:10\u001b[0m - \u001b[34mutils.data_manager\u001b[0m - \u001b[1;30mINFO\u001b[0m - Téléchargement de SAN.PA (2020-01-01 à 2025-10-31, 1d)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCÈS: 768 lignes chargées pour TTE.PA\n",
      "--- Chargement SAN.PA ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-01 12:45:10\u001b[0m - \u001b[34mutils.data_manager\u001b[0m - \u001b[1;30mINFO\u001b[0m - Données téléchargées avec succès pour SAN.PA (1496 lignes).\n",
      "\u001b[32m2025-11-01 12:45:10\u001b[0m - \u001b[34mutils.data_manager\u001b[0m - \u001b[1;30mINFO\u001b[0m - [OK] Données prêtes pour SAN.PA (768 lignes de 2022-01-01 à 2024-12-31).\n",
      "\u001b[32m2025-11-01 12:45:10\u001b[0m - \u001b[34mutils.data_manager\u001b[0m - \u001b[1;30mWARNING\u001b[0m - \u001b[33mIndex invalide dans C:\\Users\\saill\\Desktop\\t_project\\data\\cache\\OR.PA_1d.csv. Re-téléchargement.\u001b[0m\n",
      "\u001b[32m2025-11-01 12:45:10\u001b[0m - \u001b[34mutils.data_manager\u001b[0m - \u001b[1;30mINFO\u001b[0m - Téléchargement pour OR.PA (plage par défaut : 2020-01-01 à 2025-10-31)...\n",
      "\u001b[32m2025-11-01 12:45:10\u001b[0m - \u001b[34mutils.data_manager\u001b[0m - \u001b[1;30mINFO\u001b[0m - Téléchargement de OR.PA (2020-01-01 à 2025-10-31, 1d)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCÈS: 768 lignes chargées pour SAN.PA\n",
      "--- Chargement OR.PA ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-01 12:45:11\u001b[0m - \u001b[34mutils.data_manager\u001b[0m - \u001b[1;30mINFO\u001b[0m - Données téléchargées avec succès pour OR.PA (1496 lignes).\n",
      "\u001b[32m2025-11-01 12:45:11\u001b[0m - \u001b[34mutils.data_manager\u001b[0m - \u001b[1;30mINFO\u001b[0m - [OK] Données prêtes pour OR.PA (768 lignes de 2022-01-01 à 2024-12-31).\n",
      "\u001b[32m2025-11-01 12:45:11\u001b[0m - \u001b[34mutils.data_manager\u001b[0m - \u001b[1;30mWARNING\u001b[0m - \u001b[33mIndex invalide dans C:\\Users\\saill\\Desktop\\t_project\\data\\cache\\AIR.PA_1d.csv. Re-téléchargement.\u001b[0m\n",
      "\u001b[32m2025-11-01 12:45:11\u001b[0m - \u001b[34mutils.data_manager\u001b[0m - \u001b[1;30mINFO\u001b[0m - Téléchargement pour AIR.PA (plage par défaut : 2020-01-01 à 2025-10-31)...\n",
      "\u001b[32m2025-11-01 12:45:11\u001b[0m - \u001b[34mutils.data_manager\u001b[0m - \u001b[1;30mINFO\u001b[0m - Téléchargement de AIR.PA (2020-01-01 à 2025-10-31, 1d)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCÈS: 768 lignes chargées pour OR.PA\n",
      "--- Chargement AIR.PA ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-01 12:45:11\u001b[0m - \u001b[34mutils.data_manager\u001b[0m - \u001b[1;30mINFO\u001b[0m - Données téléchargées avec succès pour AIR.PA (1496 lignes).\n",
      "\u001b[32m2025-11-01 12:45:11\u001b[0m - \u001b[34mutils.data_manager\u001b[0m - \u001b[1;30mINFO\u001b[0m - [OK] Données prêtes pour AIR.PA (768 lignes de 2022-01-01 à 2024-12-31).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCÈS: 768 lignes chargées pour AIR.PA\n",
      "\n",
      "--- RAPPORT DU TEST BATCH ---\n",
      "Téléchargements réussis: 10 / 10\n",
      "Échecs: 0\n"
     ]
    }
   ],
   "source": [
    "# Liste de tickers (5 S&P 500, 5 CAC 40)\n",
    "# (Basé sur les fichiers config/markets/ que nous avons créés)\n",
    "sp500_sample = [\"AAPL\", \"MSFT\", \"GOOG\", \"TSLA\", \"NVDA\"]\n",
    "cac40_sample = [\"MC.PA\", \"TTE.PA\", \"SAN.PA\", \"OR.PA\", \"AIR.PA\"]\n",
    "all_tickers = sp500_sample + cac40_sample\n",
    "\n",
    "print(f\"Début du test de chargement en batch pour {len(all_tickers)} tickers...\")\n",
    "\n",
    "data_store = {}\n",
    "failed_tickers = []\n",
    "\n",
    "for ticker in all_tickers:\n",
    "    print(f\"--- Chargement {ticker} ---\")\n",
    "    try:\n",
    "        df = dm.get_data(\n",
    "            ticker=ticker, \n",
    "            start_date=start_date, \n",
    "            end_date=end_date, \n",
    "            use_cache=True\n",
    "        )\n",
    "        \n",
    "        if df.empty:\n",
    "            print(f\"ÉCHEC: Pas de données retournées pour {ticker}\")\n",
    "            failed_tickers.append(ticker)\n",
    "        else:\n",
    "            print(f\"SUCCÈS: {len(df)} lignes chargées pour {ticker}\")\n",
    "            data_store[ticker] = df\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"ERREUR CRITIQUE pour {ticker}: {e}\")\n",
    "        failed_tickers.append(ticker)\n",
    "\n",
    "print(\"\\n--- RAPPORT DU TEST BATCH ---\")\n",
    "print(f\"Téléchargements réussis: {len(data_store)} / {len(all_tickers)}\")\n",
    "if failed_tickers:\n",
    "    print(f\"Échecs: {failed_tickers}\")\n",
    "else:\n",
    "    print(\"Échecs: 0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Si toutes les cellules ci-dessus se sont exécutées sans erreur :\n",
    "\n",
    "1.  Le `DataManager` est capable de télécharger, mettre en cache et recharger les données.\n",
    "2.  Les indicateurs (`pandas-ta`) sont correctement calculés et ajoutés.\n",
    "3.  Le `DataProcessor` (pour les rendements) fonctionne.\n",
    "4.  Les données semblent propres (pas de NaNs, pas d'outliers évidents de splits).\n",
    "\n",
    "Nous sommes prêts à passer à la Phase 3 : Développement des Stratégies."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
